# 海量数据面试

## bloom filter
* 要点：牺牲一定的准确率，换来空间的优化。。使用一个长度为m的数组和k个hash函数
* 题目：找出2个大文件相同的行
* 对较大的文件，每行进行k次hash，并将k个结果对应位置设置为1，对较小的文件，每行进行k次hash，若
  对应位置都是1，则存在重复
  
## hash
* 要点：内存限制，将大文件hash分到若干个小文件中
* 每个小文件中进行hashmap

## MR